# 实验结果分析

## 一、矩阵与向量内积性能测试结果

以下是矩阵与向量内积的平凡算法和cache优化算法的性能测试结果：

| 矩阵大小 | 平凡算法(ms) | cache优化算法(ms) | 性能提升 |
|---------|------------|---------------|---------|
| 500     | 0.387094   | 0.196744      | 1.967501|
| 1000    | 2.055870   | 0.600740      | 3.422229|
| 1500    | 4.247933   | 1.181162      | 3.596402|
| 2000    | 12.915826  | 2.366754      | 5.457190|
| 2500    | 21.973302  | 3.637683      | 6.040466|
| 3000    | 50.928063  | 5.040877      | 10.103016|

### 分析：

1. **性能差异显著**：cache优化算法比平凡算法快1.97倍到10.1倍不等，且随着矩阵规模增大，性能差距越来越大。

2. **规模影响分析**：
   - 当矩阵大小为500时，性能提升约为1.97倍
   - 当矩阵大小为3000时，性能提升达到了惊人的10.1倍

3. **性能提升原因**：
   - 平凡算法按列访问矩阵，不符合内存中数据的行主序存储方式，导致cache命中率低
   - cache优化算法按行访问矩阵，符合行主序存储方式，具有良好的空间局部性，提高了cache命中率
   - 随着矩阵规模增大，超过cache大小后，平凡算法性能下降更为明显，而优化算法依然能较好地利用cache

4. **性能曲线**：
   - 平凡算法：随着矩阵大小增加，执行时间呈现超线性增长
   - cache优化算法：随着矩阵大小增加，执行时间增长较为平缓

## 二、n个数求和性能测试结果

以下是n个数求和的平凡算法、双链路算法和递归算法的性能测试结果：

| 数组大小 | 平凡算法(ms) | 双链路算法(ms) | 递归算法(ms) | 双链路加速比 | 递归加速比 |
|---------|------------|--------------|------------|----------|---------|
| 2^16    | 0.029203   | 0.021797     | 0.064261   | 1.339772 | 0.454444|
| 2^18    | 0.242687   | 0.149264     | 0.158902   | 1.625891 | 1.527275|
| 2^20    | 0.426924   | 0.415508     | 1.952427   | 1.027475 | 0.218663|
| 2^22    | 1.952981   | 1.659279     | 8.196332   | 1.177006 | 0.238275|
| 2^24    | 7.386442   | 7.640102     | 72.448003  | 0.966799 | 0.101955|

### 分析：

1. **双链路算法性能**：
   - 在较小规模(2^16和2^18)时，双链路算法比平凡算法快约1.3-1.6倍
   - 随着规模增大，性能优势逐渐减小，在2^24规模时甚至略微低于平凡算法
   - 这可能是因为在大规模时，指令级并行带来的收益被内存访问的开销所抵消

2. **递归算法性能**：
   - 除了在2^18规模时接近平凡算法的性能，其他规模下递归算法都比平凡算法慢
   - 在较大规模下(2^24)，递归算法比平凡算法慢约10倍
   - 性能较差的原因可能是递归算法涉及大量的数组复制和临时空间分配，导致内存开销较大

3. **规模影响分析**：
   - 对于双链路算法，性能优势随规模增大而减小
   - 对于递归算法，性能下降随规模增大而更加显著

4. **算法适用场景**：
   - 双链路算法：适合中小规模数据，可以有效利用指令级并行
   - 递归算法：在当前实现下不具备优势，可能需要进一步优化

## 三、综合分析与结论

1. **内存访问模式的重要性**：
   - 矩阵向量内积实验清楚地表明，合理的内存访问模式可以显著提高性能
   - cache优化算法通过改变访问模式，获得了高达10倍的性能提升

2. **指令级并行与内存访问的权衡**：
   - n个数求和实验展示了指令级并行可以带来一定性能提升，但提升有限
   - 当数据规模增大时，内存访问成为主要瓶颈，指令级并行带来的收益减少

3. **不同优化策略的适用场景**：
   - 空间局部性优化(cache优化)：对涉及大规模数据访问的算法效果显著
   - 指令级并行优化(双链路)：对计算密集型且数据规模不是特别大的场景有效

4. **体系结构对算法性能的影响**：
   - 现代计算机的cache层次结构使得空间局部性成为影响性能的关键因素
   - 超标量处理器的指令级并行能力可以提升性能，但提升有限且受数据访问模式影响

5. **优化建议**：
   - 针对矩阵运算：应优先考虑内存访问模式，尽量按行主序访问
   - 针对求和类操作：在中小规模数据上可以考虑使用双链路算法提高指令级并行度
   - 递归算法实现需要重新考虑，减少内存分配和数据移动 