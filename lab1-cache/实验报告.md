# 体系结构相关实验分析报告

## 一、矩阵与向量内积

### （一）算法设计

#### 1. 平凡算法设计思路

平凡算法采用逐列访问矩阵元素的方式计算矩阵与向量的内积。对于每一列，遍历该列的所有元素，与向量对应位置的元素相乘并累加，得到一个内积结果。

```c++
for(i = 0; i < n; i++) {
    sum[i] = 0.0;
    for(j = 0; j < n; j++)
        sum[i] += matrix[j][i] * vector[j];
}
```

#### 2. cache优化算法设计思路

cache优化算法改为逐行访问矩阵元素，利用空间局部性原理提高cache命中率。对于每一行元素，计算其与向量对应位置元素的乘积，并将结果累加到对应列的内积结果中。

```c++
for(i = 0; i < n; i++)
    sum[i] = 0.0;
for(j = 0; j < n; j++)
    for(i = 0; i < n; i++)
        sum[i] += matrix[j][i] * vector[j];
```

### （二）编程实现

#### 1. 平凡算法

```cpp
void column_access(int n) {
    for (int i = 0; i < n; i++) {
        result_normal[i] = 0;
        for (int j = 0; j < n; j++) {
            result_normal[i] += matrix[j][i] * vector_data[j];
        }
    }
}
```

#### 2. cache优化算法

```cpp
void row_access(int n) {
    for (int i = 0; i < n; i++) {
        result_cache[i] = 0;
    }
    
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            result_cache[j] += matrix[i][j] * vector_data[i];
        }
    }
}
```

### （三）性能测试

对平凡算法和cache优化算法进行测试，测试不同问题规模（矩阵大小）对性能的影响。为提高测量精度，每种规模重复多次测试并取平均值。

#### 测试方法

使用C++的高精度计时函数`std::chrono::high_resolution_clock`测量算法执行时间。

```cpp
int64_t measure_time(void (*func)(int), int n, int repeat) {
    auto start = std::chrono::high_resolution_clock::now();
    
    for (int i = 0; i < repeat; i++) {
        func(n);
    }
    
    auto end = std::chrono::high_resolution_clock::now();
    return std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count() / repeat;
}
```

#### 测试结果

| 矩阵大小 | 平凡算法(ms) | cache优化算法(ms) | 性能提升 |
|---------|------------|---------------|---------|
| 500     | 0.387094   | 0.196744      | 1.967501|
| 1000    | 2.055870   | 0.600740      | 3.422229|
| 1500    | 4.247933   | 1.181162      | 3.596402|
| 2000    | 12.915826  | 2.366754      | 5.457190|
| 2500    | 21.973302  | 3.637683      | 6.040466|
| 3000    | 50.928063  | 5.040877      | 10.103016|

此外，我们使用Linux perf工具对程序进行了更详细的分析，得到了以下结果：

| 测试程序 | 平凡算法(秒) | cache优化算法(秒) |
|---------|------------|----------------|
| 矩阵大小2000 | 0.1117 | 0.0627 |

### （四）profiling分析

使用Linux的perf工具对程序进行了分析。虽然WSL2环境下无法直接获取硬件计数器信息，但我们仍然能通过perf report获取一些有用的信息：

#### 平凡算法

```
# Samples: 182  of event 'cpu-clock:pppH'
# Event count (approx.): 45500000
#
# Children      Self  Command        Shared Object         Symbol                                    
# ........  ........  .............  ....................  ..........................................
#
    82.97%    82.97%  matrix_vector  matrix_vector         [.] _Z13column_accessi
            |
            ---_Z13column_accessi

    10.99%     0.00%  matrix_vector  [kernel.kallsyms]     [k] asm_exc_page_fault
```

从报告中可以看出：
- 平凡算法中82.97%的CPU时间花在了`column_access`函数上
- 有10.99%的时间花在了处理页面错误（page fault）上，这表明内存访问模式不够高效

#### cache优化算法

```
# Samples: 95  of event 'cpu-clock:pppH'
# Event count (approx.): 23750000
#
# Children      Self  Command        Shared Object         Symbol                            
# ........  ........  .............  ....................  ..................................
#
    66.32%     4.21%  matrix_vector  matrix_vector         [.] main
            |
            ---main
               |          
                --62.11%--asm_exc_page_fault
```

分析报告显示：
- cache优化算法的CPU时间分布更为分散，没有像平凡算法那样集中在单一函数
- 相比平凡算法，程序的总体执行时间减少了约44%（从45500000降至23750000）

### （五）结果分析

1. cache优化算法比平凡算法平均快2倍到10倍以上，且随着问题规模增大，性能差距更明显。
2. 从性能测试结果可以看出，平凡算法随矩阵大小增长呈超线性增长，而优化算法增长较为平缓。
3. 平凡算法逐列访问矩阵元素，导致内存不连续访问，cache命中率低；而优化算法逐行访问，符合行主序存储方式，具有良好的空间局部性。
4. 当矩阵大小达到3000x3000时，优化算法比平凡算法快了10倍多，这表明随着数据规模增大，cache的影响变得更加显著。
5. perf报告显示平凡算法中出现了更多的页面错误，这证实了我们的分析：不连续的内存访问模式会导致更多的cache缺失和页面错误。

## 二、n个数求和

### （一）算法设计

#### 1. 平凡算法设计思路

平凡算法采用单链路的方式，将n个数逐个累加到结果变量中。

```c++
int sum = 0;
for(i = 0; i < n; i++)
    sum += a[i];
```

#### 2. 超标量优化算法设计思路

1. 双链路算法：将累加操作分为两个独立的链路，减少指令依赖
   ```c++
   int sum1 = 0, sum2 = 0;
   for(i = 0; i < n; i += 2) {
       sum1 += a[i];
       sum2 += a[i+1];
   }
   sum = sum1 + sum2;
   ```

2. 递归算法：采用分治思想，将n个数两两相加，递归处理
   ```c++
   for(m = n; m > 1; m = (m+1)/2)
       for(i = 0; i < (m+1)/2; i++)
           a[i] = a[i*2] + a[i*2+1];
   // a[0]为最终结果
   ```

### （二）编程实现

#### 1. 平凡算法

```cpp
void single_link(int n) {
    int res = 0;
    for (int i = 0; i < n; i++) {
        res += data[i];
    }
    result = res;
}
```

#### 2. 超标量优化算法

双链路算法：
```cpp
void double_link(int n) {
    int res1 = 0, res2 = 0;
    for (int i = 0; i < n; i += 2) {
        res1 += data[i];
        res2 += data[i + 1];
    }
    result = res1 + res2;
}
```

递归算法：
```cpp
void recursive_sum(int n) {
    // 确保n是2的幂
    int m = 1;
    while (m < n) m *= 2;
    
    // 复制数据到临时数组
    int* temp = new int[m];
    for (int i = 0; i < n; i++) {
        temp[i] = data[i];
    }
    for (int i = n; i < m; i++) {
        temp[i] = 0; // 补零
    }
    
    // 两两相加
    for (int step = m; step > 1; step /= 2) {
        for (int i = 0; i < step/2; i++) {
            temp[i] = temp[i*2] + temp[i*2 + 1];
        }
    }
    
    result = temp[0];
    delete[] temp;
}
```

### （三）性能测试

#### 测试方法

与实验一相同，使用高精度计时函数测量算法执行时间。为减少随机误差，重复执行多次并取平均值。

#### 测试结果

| 数组大小 | 平凡算法(ms) | 双链路算法(ms) | 递归算法(ms) | 双链路加速比 | 递归加速比 |
|---------|------------|--------------|------------|----------|---------|
| 2^16    | 0.029203   | 0.021797     | 0.064261   | 1.339772 | 0.454444|
| 2^18    | 0.242687   | 0.149264     | 0.158902   | 1.625891 | 1.527275|
| 2^20    | 0.426924   | 0.415508     | 1.952427   | 1.027475 | 0.218663|
| 2^22    | 1.952981   | 1.659279     | 8.196332   | 1.177006 | 0.238275|
| 2^24    | 7.386442   | 7.640102     | 72.448003  | 0.966799 | 0.101955|

此外，我们使用Linux perf工具对程序进行了更详细的分析，得到了以下结果：

| 测试程序 | 平凡算法(秒) | 双链路算法(秒) | 递归算法(秒) |
|---------|------------|--------------|-----------|
| n = 2^22 | 0.0394 | 0.0381 | 0.0416 |

### （四）profiling分析

使用Linux的perf工具对程序进行了分析。虽然在WSL2环境下无法直接获取硬件计数器信息，但我们可以从执行时间和系统时间分布上看出一些差异：

#### 平凡算法

```
 Performance counter stats for './sum_array 1 22':
       0.039411778 seconds time elapsed
       0.008113000 seconds user
       0.008113000 seconds sys
```

#### 双链路算法

```
 Performance counter stats for './sum_array 2 22':
       0.038121167 seconds time elapsed
       0.007923000 seconds user
       0.007923000 seconds sys
```

#### 递归算法

```
 Performance counter stats for './sum_array 3 22':
       0.041620271 seconds time elapsed
       0.010369000 seconds user
       0.010369000 seconds sys
```

从执行时间来看：
- 双链路算法略快于平凡算法，用户和系统时间也略少
- 递归算法比另外两种算法慢，且用户和系统时间更多，这可能是由于额外的内存操作和函数调用开销

### （五）结果分析

1. 双链路算法在小规模数据下比平凡算法快1.3~1.6倍，但随着数据规模增大，性能优势逐渐消失，甚至在最大规模下略微低于平凡算法。
2. 递归算法在我们的实现下性能表现不佳，这可能是由于大量的内存分配和数据移动带来的开销。
3. 实验结果表明，对于n个数求和这样的简单操作，指令级并行能带来一定的性能提升，但提升有限且受数据规模影响。
4. 递归算法理论上可以更好地利用指令级并行，但实际实现中的额外开销抵消了这一优势。
5. perf分析结果显示，递归算法确实有更多的系统和用户时间，这证实了我们的分析：额外的内存操作和递归调用导致开销增加。

## 三、实验总结与思考

### （一）两个实验的异同点

#### 相同点
1. 都涉及体系结构对算法性能的影响
2. 都通过改变数据访问模式或计算方式优化性能
3. 都利用计算机硬件特性（cache、超标量）提高效率

#### 不同点
1. 实验一主要关注空间局部性，利用cache加速；实验二主要关注时间局部性，利用指令级并行加速
2. 实验一优化获得的性能提升更大（最高10倍以上），实验二优化获得的性能提升相对较小（最高1.6倍左右）
3. 实验一的优化效果随问题规模增大而增强，实验二的优化效果随问题规模增大而减弱

### （二）总结

1. 现代计算机体系结构中，内存访问是影响程序性能的关键因素之一
2. 合理设计数据访问模式，可以显著提高程序性能：
   - 利用空间局部性原理，使内存访问连续，提高cache命中率
   - 利用时间局部性原理，减少指令依赖，提高指令级并行度
3. 矩阵向量内积实验清楚地表明，合理的内存访问模式可以带来高达10倍的性能提升
4. n个数求和实验表明，指令级并行可以提供一定的性能提升，但提升有限且受数据规模影响
5. 当操作涉及大规模数据时，内存访问模式的优化通常比指令级并行的优化更为重要
6. perf工具分析结果验证了我们的推断：平凡算法中存在更多的页面错误和内存访问不连续问题，而优化算法具有更好的内存访问模式

通过本次实验，我深入理解了计算机体系结构对程序性能的影响，掌握了如何根据体系结构特性优化算法，以及如何使用高精度计时工具和性能分析工具测量和分析程序性能。这些知识和技能对今后的并行程序设计和优化具有重要指导意义。 