#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NTTæ€§èƒ½æµ‹è¯•å¯è§†åŒ–è„šæœ¬ - ä¸­æ–‡å­—ä½“ä¼˜åŒ–ç‰ˆæœ¬
åŸºäºç³»ç»Ÿå®é™…å­—ä½“æƒ…å†µä¼˜åŒ–é…ç½®
"""

import os
import warnings
warnings.filterwarnings('ignore')

import matplotlib
matplotlib.use('Agg')

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import pandas as pd
import numpy as np
import glob
import seaborn as sns
import logging
import argparse
from collections import defaultdict

# å…¨å±€å®šä¹‰è¾“å‡ºç›®å½•
OUTPUT_DIR = "fig"

# ç¦ç”¨å­—ä½“ç›¸å…³æ—¥å¿—
logging.getLogger('matplotlib.font_manager').setLevel(logging.CRITICAL)

def setup_optimal_chinese_font():
    print("ğŸ”§ è®¾ç½®æœ€ä¼˜ä¸­æ–‡å­—ä½“é…ç½®...")
    font_files = [
        '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
        '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
        '/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc'
    ]
    
    for font_path in font_files:
        if os.path.exists(font_path):
            try:
                fm.fontManager.addfont(font_path)
            except:
                pass
    
    plt.rcParams['font.sans-serif'] = [
        'WenQuanYi Zen Hei',
        'Noto Sans CJK JP',
        'Noto Serif CJK JP',
        'DejaVu Sans',
        'sans-serif'
    ]
    
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['figure.figsize'] = (12, 8)
    plt.rcParams['savefig.dpi'] = 300
    plt.rcParams['savefig.bbox'] = 'tight'
    
    try:
        fig, ax = plt.subplots(figsize=(1, 1))
        ax.text(0.5, 0.5, 'ä¸­æ–‡æµ‹è¯•', fontsize=1)
        plt.close(fig)
        print("âœ… ä¸­æ–‡å­—ä½“é…ç½®æˆåŠŸ")
        print(f"ğŸ“ ä¸»è¦å­—ä½“: {plt.rcParams['font.sans-serif'][0]}")
        return True
    except:
        print("âš ï¸ å­—ä½“é…ç½®æœ‰é—®é¢˜ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
        return False

font_success = setup_optimal_chinese_font()

sns.set_style("whitegrid", {"font.sans-serif": plt.rcParams['font.sans-serif']})
sns.set_palette("husl")

def load_performance_data(csv_file_path):
    try:
        data = pd.read_csv(csv_file_path)
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šCSVæ–‡ä»¶æœªæ‰¾åˆ°äº {csv_file_path}")
        return None
    
    # ä½¿ç”¨CSVä¸­çš„å®é™…åˆ—å "å¹³å‡æ—¶é—´(ç§’)"
    actual_time_column_name = "å¹³å‡æ—¶é—´(ç§’)"
    if actual_time_column_name not in data.columns:
        print(f"é”™è¯¯ï¼šCSVæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœŸæœ›çš„åˆ— '{actual_time_column_name}'")
        print(f"å¯ç”¨çš„åˆ—: {data.columns.tolist()}")
        # å°è¯•å¤‡ç”¨è‹±æ–‡åï¼Œä»¥é˜²ä¸‡ä¸€
        if "Time" in data.columns:
            print("å°è¯•ä½¿ç”¨å¤‡ç”¨åˆ—å 'Time'")
            actual_time_column_name = "Time"
        else:
            return None # å¦‚æœå…³é”®åˆ—ç¼ºå¤±ï¼Œåˆ™æ— æ³•ç»§ç»­

    data['Time'] = pd.to_numeric(data[actual_time_column_name], errors='coerce')
    data.dropna(subset=['Time'], inplace=True)

    # åŒæ ·ï¼Œæ£€æŸ¥å…¶ä»–åˆ—åï¼Œè¿™é‡Œå‡è®¾å®ƒä»¬æ˜¯ "è§„æ¨¡", "çº¿ç¨‹æ•°", "å®ç°", "æ¨¡æ•°"
    # å¦‚æœè¿™äº›åˆ—ååœ¨CSVä¸­ä¹Ÿæ˜¯ä¸­æ–‡ï¼Œä¹Ÿéœ€è¦ç›¸åº”è°ƒæ•´
    actual_size_column_name = "è§„æ¨¡"
    actual_threads_column_name = "çº¿ç¨‹æ•°"
    actual_impl_column_name = "å®ç°"
    actual_modulus_column_name = "æ¨¡æ•°"

    # é‡å‘½ååˆ—ä¸ºä»£ç ä¸­æœŸæœ›çš„è‹±æ–‡åï¼Œä»¥ä¾¿åç»­ä»£ç ç»Ÿä¸€å¤„ç†
    rename_map = {
        actual_time_column_name: 'Time',
        actual_size_column_name: 'Size',
        actual_threads_column_name: 'Threads',
        actual_impl_column_name: 'Implementation',
        actual_modulus_column_name: 'Modulus'
        # å¦‚æœè¿˜æœ‰å…¶ä»–åˆ—ï¼Œä¾‹å¦‚ "æ ‡å‡†å·®", "ç»“æœéªŒè¯" ç­‰ï¼Œä¹Ÿå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ˜ å°„
        # "æ ‡å‡†å·®": "StdDev",
        # "ç»“æœéªŒè¯": "ValidationStatus"
    }
    data.rename(columns=rename_map, inplace=True)

    # Ensure 'Time' column is unique after renaming, keep the first if duplicates exist
    if isinstance(data.columns, pd.MultiIndex):
        # If columns are MultiIndex, this logic might need adjustment based on its structure
        # For now, assume we are dealing with a flat column index for typical CSVs
        pass
    elif 'Time' in data.columns:
        time_cols = [col for col in data.columns if col == 'Time']
        if len(time_cols) > 1:
            print(f"è­¦å‘Š: åœ¨load_performance_dataä¸­å‘ç°é‡å¤çš„ 'Time' åˆ— ({len(time_cols)}ä¸ª)ã€‚å°†åªä¿ç•™ç¬¬ä¸€ä¸ªã€‚")
            # Get all columns, then reorder to keep the first 'Time' and other unique columns
            cols = list(data.columns)
            first_time_idx = cols.index('Time')
            cols_to_keep = []
            seen_time = False
            for i, col_name in enumerate(cols):
                if col_name == 'Time':
                    if not seen_time:
                        cols_to_keep.append(col_name)
                        seen_time = True
                else:
                    if col_name not in cols_to_keep: # Keep other unique columns
                         cols_to_keep.append(col_name)
            data = data[cols_to_keep]

    # ç°åœ¨å¯ä»¥å®‰å…¨åœ°ä½¿ç”¨ 'Size', 'Threads', 'Implementation', 'Modulus'
    data['Size'] = data['Size'].astype(int)
    data['Threads'] = data['Threads'].astype(int)
    
    def get_base_impl(name):
        if 'crt_arbitrary' in name:
            return name.split('_crt_arbitrary_')[-1] + '_crt'
        return name.replace('ntt_', '') # ç®€åŒ–åç§°

    data['BaseImpl'] = data['Implementation'].apply(get_base_impl)
    data['FullImpl'] = data['Implementation'] # ä¿å­˜åŸå§‹å®ç°åç§°

    def sanitize_modulus(mod):
        if isinstance(mod, str) and mod.upper() == "CRT":
            return "CRT"
        try:
            return int(mod)
        except ValueError:
            return str(mod) # ä¿ç•™æ— æ³•è½¬æ¢çš„å­—ç¬¦ä¸²å½¢å¼

    data['Modulus'] = data['Modulus'].apply(sanitize_modulus)
    
    return data

def create_chinese_performance_charts(data):
    if data is None or data.empty:
        print("æ— æ•°æ®å¯ä¾›ç»˜å›¾ã€‚")
        return {}

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    chart_paths = {}

    # Calculate average performance
    # Using as_index=False to ensure 'FullImpl' is a column, then mean should produce a DataFrame with 'FullImpl' and 'Time'
    avg_performance_df = data.groupby('FullImpl', as_index=False)['Time'].mean()

    # --- Debugging Start ---
    # print("\n--- Debugging avg_performance_df ---")
    # print(f"Columns of avg_performance_df: {avg_performance_df.columns.tolist()}")
    # print("Head of avg_performance_df:")
    # print(avg_performance_df.head())
    # print("--- Debugging End ---\n")
    # --- Debugging End ---

    # Correct avg_performance_df columns if 'Time' is duplicated
    if list(avg_performance_df.columns) == ['FullImpl', 'Time', 'Time']:
        print("â„¹ï¸ Correcting DataFrame with duplicate 'Time' columns: selecting 'FullImpl' and the first 'Time' column.")
        avg_performance_df = avg_performance_df.iloc[:, :2] # Selects first two columns
        avg_performance_df.columns = ['FullImpl', 'Time'] # Rename them to ensure uniqueness
    elif 'Time' not in avg_performance_df.columns:
        # This case should ideally not be reached if groupby worked as expected or data loading was correct
        print(f"âŒå…³é”®é”™è¯¯: 'Time' åˆ—åœ¨ avg_performance_df ä¸­ä¸å­˜åœ¨ã€‚æ£€æµ‹åˆ°çš„åˆ—: {avg_performance_df.columns.tolist()}")
        print(f"avg_performance_df çš„å†…å®¹:\n{avg_performance_df.head()}")
        return {} # Cannot proceed

    # Now avg_performance_df should be a DataFrame with columns 'FullImpl' and 'Time' (mean of original Time)
    # Sort this DataFrame by the 'Time' column
    avg_performance_sorted_df = avg_performance_df.sort_values(by='Time', ascending=True)

    # For plotting with plot(kind='bar'), we need a Series where index is 'FullImpl' and values are 'Time'
    avg_performance_series = avg_performance_sorted_df.set_index('FullImpl')['Time']
        
    plt.figure(figsize=(12, 7))
    avg_performance_series.plot(kind='bar', color=['skyblue', 'lightcoral', 'lightgreen', 'gold', 'orchid', 'turquoise'])
    plt.title('å„ç§NTTå®ç°çš„å¹³å‡æ‰§è¡Œæ—¶é—´å¯¹æ¯”', fontsize=16)
    plt.xlabel('å®ç°æ–¹æ³•', fontsize=14)
    plt.ylabel('å¹³å‡æ‰§è¡Œæ—¶é—´ (ç§’)', fontsize=14)
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()
    path = os.path.join(OUTPUT_DIR, "avg_performance_comparison_chinese.png")
    plt.savefig(path)
    plt.close()
    chart_paths['avg_performance'] = path
    print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {path}")

    selected_impls = [
        'ntt_serial', 'ntt_pthread', 'ntt_openmp',
        'ntt_crt_arbitrary_serial', 'ntt_crt_arbitrary_pthread', 'ntt_crt_arbitrary_openmp'
    ]
    selected_impls = [impl for impl in selected_impls if impl in data['FullImpl'].unique()]

    if selected_impls:
        max_threads_data = data.loc[data.groupby(['FullImpl', 'Size'])['Threads'].idxmax()]
        serial_data = data[data['Threads'] == 1]
        plot_data_size_impact = pd.concat([max_threads_data[max_threads_data['FullImpl'].isin(selected_impls)],
                                           serial_data[serial_data['FullImpl'].isin(selected_impls)]])
        plot_data_size_impact.drop_duplicates(subset=['FullImpl', 'Size'], keep='first', inplace=True)


        pivot_data_size = plot_data_size_impact.pivot_table(index='Size', columns='FullImpl', values='Time', aggfunc='mean')
        
        if not pivot_data_size.empty:
            pivot_data_size.plot(kind='bar', figsize=(14, 8), colormap='viridis')
            plt.title('ä¸åŒé—®é¢˜è§„æ¨¡ (N) ä¸‹å„å®ç°æ€§èƒ½å¯¹æ¯” (æœ€å¤§çº¿ç¨‹æ•°/ä¸²è¡Œ)', fontsize=16)
            plt.xlabel('é—®é¢˜è§„æ¨¡ (N)', fontsize=14)
            plt.ylabel('å¹³å‡æ‰§è¡Œæ—¶é—´ (ç§’)', fontsize=14)
            plt.xticks(rotation=45)
            plt.legend(title='å®ç°æ–¹æ³•', bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.tight_layout()
            path = os.path.join(OUTPUT_DIR, "size_impact_on_performance_chinese.png")
            plt.savefig(path)
            plt.close()
            chart_paths['size_impact'] = path
            print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {path}")
        else:
            print("è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ä¸º 'size_impact_on_performance_chinese.png' ç”Ÿæˆé€è§†è¡¨ã€‚")


    parallel_impls = [impl for impl in selected_impls if 'serial' not in impl]
    if parallel_impls:
        if data['Size'].nunique() > 1:
            target_size = data['Size'].quantile(0.5, interpolation='nearest') # ä¸­ä½æ•°
        else:
            target_size = data['Size'].unique()[0]
        
        plain_ntt_data = data[~data['FullImpl'].str.contains('crt')]
        if not plain_ntt_data.empty:
            unique_moduli_for_plain = plain_ntt_data['Modulus'].unique()
            numeric_moduli_series = pd.to_numeric(pd.Series(unique_moduli_for_plain), errors='coerce').dropna()

            if not numeric_moduli_series.empty:
                unique_numeric_moduli = sorted(numeric_moduli_series.unique())
                target_modulus_plain = unique_numeric_moduli[len(unique_numeric_moduli) // 2]
            elif len(unique_moduli_for_plain) > 0:
                target_modulus_plain = plain_ntt_data['Modulus'].mode()[0] if not plain_ntt_data['Modulus'].mode().empty else "Unknown"
            else:
                target_modulus_plain = "Unknown"

            if target_modulus_plain == "Unknown":
                print("è­¦å‘Š: åœ¨æ™®é€šNTTæ•°æ®ä¸­æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡æ•°ç”¨äºçº¿ç¨‹å½±å“å›¾ã€‚")
            else:
                data_for_thread_plot_plain = plain_ntt_data[
                    (plain_ntt_data['FullImpl'].isin(parallel_impls)) &
                    (plain_ntt_data['Size'] == target_size) &
                    (plain_ntt_data['Modulus'] == target_modulus_plain)
                ]

                if not data_for_thread_plot_plain.empty:
                    pivot_data_threads_plain = data_for_thread_plot_plain.pivot_table(index='Threads', columns='FullImpl', values='Time', aggfunc='mean')
                    if not pivot_data_threads_plain.empty:
                        pivot_data_threads_plain.plot(kind='line', marker='o', figsize=(12, 7))
                        plt.title(f'ä¸åŒçº¿ç¨‹æ•°å¯¹æ™®é€šNTTæ€§èƒ½çš„å½±å“ (N={target_size}, P={target_modulus_plain})', fontsize=16)
                        plt.xlabel('çº¿ç¨‹æ•°', fontsize=14)
                        plt.ylabel('å¹³å‡æ‰§è¡Œæ—¶é—´ (ç§’)', fontsize=14)
                        plt.xticks(data_for_thread_plot_plain['Threads'].unique())
                        plt.legend(title='å®ç°æ–¹æ³•')
                        plt.grid(True)
                        path = os.path.join(OUTPUT_DIR, f"thread_impact_on_performance_plain_N{target_size}_P{str(target_modulus_plain).replace('.', '_')}_chinese.png")
                        plt.savefig(path)
                        plt.close()
                        chart_paths['thread_impact_plain'] = path
                        print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {path}")
                    else:
                        print(f"è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿæ•°æ®ä¸ºæ™®é€šNTTçº¿ç¨‹å½±å“å›¾ (N={target_size}, P={target_modulus_plain}) ç”Ÿæˆé€è§†è¡¨ã€‚")
                else:
                    print(f"è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿæ•°æ®ç»˜åˆ¶æ™®é€šNTTçº¿ç¨‹æ•°å½±å“å›¾ (N={target_size}, P={target_modulus_plain})ã€‚")
        else:
            print("è­¦å‘Š: æ²¡æœ‰æ™®é€šNTTæ•°æ®å¯ä¾›ç»˜åˆ¶çº¿ç¨‹æ•°å½±å“å›¾ã€‚")

        crt_ntt_data = data[data['FullImpl'].str.contains('crt_arbitrary')]
        if not crt_ntt_data.empty:
            if crt_ntt_data['Modulus'].nunique() > 1:
                potential_moduli_crt = [m for m in crt_ntt_data['Modulus'].unique() if m != "CRT"]
                if potential_moduli_crt:
                     target_modulus_crt = pd.Series(potential_moduli_crt).mode()[0]
                else:
                     target_modulus_crt = "CRT"
            else:
                target_modulus_crt = crt_ntt_data['Modulus'].unique()[0]

            data_for_thread_plot_crt = crt_ntt_data[
                (crt_ntt_data['FullImpl'].isin(parallel_impls)) &
                (crt_ntt_data['Size'] == target_size) &
                (crt_ntt_data['Modulus'] == target_modulus_crt)
            ]

            if not data_for_thread_plot_crt.empty:
                pivot_data_threads_crt = data_for_thread_plot_crt.pivot_table(index='Threads', columns='FullImpl', values='Time', aggfunc='mean')
                if not pivot_data_threads_crt.empty:
                    pivot_data_threads_crt.plot(kind='line', marker='o', figsize=(12, 7))
                    plt.title(f'ä¸åŒçº¿ç¨‹æ•°å¯¹CRT-NTTæ€§èƒ½çš„å½±å“ (N={target_size}, P_target={target_modulus_crt})', fontsize=16)
                    plt.xlabel('çº¿ç¨‹æ•°', fontsize=14)
                    plt.ylabel('å¹³å‡æ‰§è¡Œæ—¶é—´ (ç§’)', fontsize=14)
                    plt.xticks(data_for_thread_plot_crt['Threads'].unique())
                    plt.legend(title='å®ç°æ–¹æ³•')
                    plt.grid(True)
                    path = os.path.join(OUTPUT_DIR, f"thread_impact_on_performance_crt_N{target_size}_P{target_modulus_crt}_chinese.png")
                    plt.savefig(path)
                    plt.close()
                    chart_paths['thread_impact_crt'] = path
                    print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {path}")
                else:
                    print(f"è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿæ•°æ®ä¸ºCRT-NTTçº¿ç¨‹å½±å“å›¾ (N={target_size}, P_target={target_modulus_crt}) ç”Ÿæˆé€è§†è¡¨ã€‚")

            else:
                print(f"è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿæ•°æ®ç»˜åˆ¶CRT-NTTçº¿ç¨‹æ•°å½±å“å›¾ (N={target_size}, P_target={target_modulus_crt})ã€‚")
        else:
            print("è­¦å‘Š: æ²¡æœ‰CRT-NTTæ•°æ®å¯ä¾›ç»˜åˆ¶çº¿ç¨‹æ•°å½±å“å›¾ã€‚")

    return chart_paths


def create_chinese_scalability_chart(data):
    if data is None or data.empty:
        print("æ— æ•°æ®å¯ä¾›ç”Ÿæˆå¯æ‰©å±•æ€§å›¾è¡¨ã€‚")
        return {}
        
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    scalability_chart_paths = {}

    parallel_implementations = data[data['Threads'] > 1]['FullImpl'].unique()
    
    if data['Size'].nunique() > 0:
        target_size = data['Size'].quantile(0.5, interpolation='nearest') if data['Size'].nunique() > 1 else data['Size'].unique()[0]
    else:
        print("è­¦å‘Š: å¯æ‰©å±•æ€§åˆ†æç¼ºå°‘æœ‰æ•ˆçš„ 'Size' æ•°æ®ã€‚")
        return {}

    impl_categories = {
        "plain": [impl for impl in parallel_implementations if "crt" not in impl],
        "crt": [impl for impl in parallel_implementations if "crt" in impl]
    }

    for category_name, impl_list in impl_categories.items():
        if not impl_list:
            print(f"æ—  {category_name} ç±»å‹çš„å¹¶è¡Œå®ç°å¯ä¾›åˆ†æã€‚")
            continue

        category_data = data[data['FullImpl'].isin(impl_list) & (data['Size'] == target_size)]
        
        if category_data.empty:
            print(f"æ— æ•°æ®ç”¨äº {category_name} NTT åœ¨ N={target_size} æ—¶çš„å¯æ‰©å±•æ€§åˆ†æã€‚")
            continue
            
        if category_name == "plain":
            unique_moduli_for_plain = category_data['Modulus'].unique()
            numeric_moduli_series = pd.to_numeric(pd.Series(unique_moduli_for_plain), errors='coerce').dropna()
            
            target_modulus = "Unknown" # Default
            if not numeric_moduli_series.empty:
                unique_numeric_moduli = sorted(numeric_moduli_series.unique())
                target_modulus = unique_numeric_moduli[len(unique_numeric_moduli) // 2]
            elif len(unique_moduli_for_plain) > 0:
                # Fallback if no numeric, but other (e.g. string) moduli exist
                modes = category_data['Modulus'].mode()
                if not modes.empty:
                    target_modulus = modes[0]

            if target_modulus == "Unknown":
                print(f"è­¦å‘Š: {category_name} NTT åœ¨ N={target_size} æ—¶ç¼ºå°‘æœ‰æ•ˆçš„ 'Modulus' æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå¯æ‰©å±•æ€§å›¾è¡¨ã€‚")
                continue # This continue is correctly placed within the for loop over categories

            serial_impl_name_pattern = 'ntt_serial'
            plot_title_suffix = f"Plain NTT (N={target_size}, P={target_modulus})"
            filename_suffix = f"plain_N{target_size}_P{str(target_modulus).replace('.', '_')}"
        else: # CRT
            unique_moduli_for_crt = category_data['Modulus'].unique()
            numeric_crt_moduli = pd.to_numeric(pd.Series([m for m in unique_moduli_for_crt if str(m).upper() != 'CRT']), errors='coerce').dropna().unique()

            target_modulus = "UnknownCRTTarget" # Default
            if len(numeric_crt_moduli) > 0:
                target_modulus = sorted(numeric_crt_moduli)[len(numeric_crt_moduli) // 2]
            elif "CRT" in unique_moduli_for_crt:
                target_modulus = "CRT"
            elif len(unique_moduli_for_crt) > 0:
                modes = category_data['Modulus'].mode()
                if not modes.empty:
                    target_modulus = modes[0]
            
            if target_modulus == "UnknownCRTTarget":
                print(f"è­¦å‘Š: {category_name} NTT åœ¨ N={target_size} æ—¶ç¼ºå°‘æœ‰æ•ˆçš„ 'Modulus' (P_target) æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå¯æ‰©å±•æ€§å›¾è¡¨ã€‚")
                continue # This continue is correctly placed

            serial_impl_name_pattern = 'ntt_crt_arbitrary_serial'
            plot_title_suffix = f"CRT NTT (N={target_size}, P_target={target_modulus})"
            filename_suffix = f"crt_N{target_size}_P{target_modulus}"

        serial_data = data[
            (data['FullImpl'] == serial_impl_name_pattern) &
            (data['Size'] == target_size) &
            (data['Modulus'] == target_modulus)
        ]
        
        if serial_data.empty:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ° {serial_impl_name_pattern} åœ¨ N={target_size}, Modulus/P_target={target_modulus} ä¸‹çš„åŸºå‡†ä¸²è¡Œæ—¶é—´ã€‚å¯æ‰©å±•æ€§å›¾è¡¨å¯èƒ½ä¸å‡†ç¡®æˆ–æ— æ³•ç”Ÿæˆã€‚")
            approx_serial_times = {}
            for impl in impl_list:
                one_thread_data = category_data[(category_data['FullImpl'] == impl) & (category_data['Threads'] == 1) & (category_data['Modulus'] == target_modulus)]
                if not one_thread_data.empty:
                    approx_serial_times[impl] = one_thread_data['Time'].mean()
            if not approx_serial_times:
                print(f"è­¦å‘Š: æ— æ³•æ‰¾åˆ°æˆ–è¿‘ä¼¼ {category_name} NTT çš„åŸºå‡†æ—¶é—´ï¼Œè·³è¿‡å¯æ‰©å±•æ€§å›¾è¡¨ç”Ÿæˆã€‚")
                continue
            base_time_is_approximate = True
        else:
            base_serial_time = serial_data['Time'].mean()
            base_time_is_approximate = False


        plt.figure(figsize=(14, 7))

        plt.subplot(1, 2, 1)
        for impl in impl_list:
            impl_data = category_data[(category_data['FullImpl'] == impl) & (category_data['Modulus'] == target_modulus)]
            if impl_data.empty:
                print(f"è­¦å‘Š: Impl={impl}, N={target_size}, P/P_target={target_modulus} - impl_dataä¸ºç©ºï¼Œè·³è¿‡æ­¤å®ç°çš„å¯æ‰©å±•æ€§åˆ†æ(åŠ é€Ÿæ¯”éƒ¨åˆ†)ã€‚")
                continue

            current_base_time_for_impl_sp = base_serial_time 
            if base_time_is_approximate:
                if impl not in approx_serial_times:
                    print(f"è­¦å‘Š: Impl={impl}, N={target_size}, P/P_target={target_modulus} - ç¼ºå°‘è¿‘ä¼¼åŸºå‡†æ—¶é—´(åŠ é€Ÿæ¯”éƒ¨åˆ†)ã€‚è·³è¿‡æ­¤å®ç°ã€‚")
                    continue
                current_base_time_for_impl_sp = approx_serial_times[impl]
            
            # avg_time_by_threads should now be a Series due to upstream column deduplication
            avg_time_by_threads = impl_data.groupby('Threads')['Time'].mean().sort_index()

            if avg_time_by_threads.empty:
                print(f"è­¦å‘Š (æ•ˆç‡): Impl={impl}, N={target_size}, P/P_target={target_modulus} - avg_time_by_threads ä¸ºç©ºã€‚è·³è¿‡ã€‚")
                continue

            speedup = current_base_time_for_impl_sp / avg_time_by_threads
            
            # ç¡®ä¿speedupæ•°æ®æ˜¯ä¸€ç»´çš„
            if isinstance(speedup.values, np.ndarray) and speedup.values.ndim > 1:
                speedup = speedup.iloc[:, 0] if speedup.values.shape[1] > 0 else speedup.iloc[:, -1]
            
            plt.plot(speedup.index, speedup.values, marker='o', linestyle='-', label=impl.replace('ntt_', '').replace('_arbitrary',''))
        
        plt.title(f'åŠ é€Ÿæ¯” - {plot_title_suffix}{" (è¿‘ä¼¼åŸºå‡†)" if base_time_is_approximate else ""}', fontsize=14)
        plt.xlabel('çº¿ç¨‹æ•°', fontsize=12)
        plt.ylabel('åŠ é€Ÿæ¯” (Speedup)', fontsize=12)
        plt.legend()
        plt.grid(True)

        unique_threads = sorted(category_data['Threads'].unique())
        if unique_threads:
             plt.plot(unique_threads, unique_threads, linestyle='--', color='gray', label='ç†æƒ³åŠ é€Ÿæ¯”')
             plt.xticks(unique_threads)

        plt.subplot(1, 2, 2)
        for impl in impl_list:
            impl_data = category_data[(category_data['FullImpl'] == impl) & (category_data['Modulus'] == target_modulus)]
            if impl_data.empty:
                print(f"è­¦å‘Š: Impl={impl}, N={target_size}, P/P_target={target_modulus} - impl_dataä¸ºç©ºï¼Œè·³è¿‡æ­¤å®ç°çš„å¯æ‰©å±•æ€§åˆ†æ(æ•ˆç‡éƒ¨åˆ†)ã€‚")
                continue

            current_base_time_for_impl_eff = base_serial_time
            if base_time_is_approximate:
                if impl not in approx_serial_times:
                    print(f"è­¦å‘Š: Impl={impl}, N={target_size}, P/P_target={target_modulus} - ç¼ºå°‘è¿‘ä¼¼åŸºå‡†æ—¶é—´(æ•ˆç‡éƒ¨åˆ†)ã€‚è·³è¿‡æ­¤å®ç°ã€‚")
                    continue
                current_base_time_for_impl_eff = approx_serial_times[impl]
            
            # avg_time_by_threads should now be a Series due to upstream column deduplication
            avg_time_by_threads = impl_data.groupby('Threads')['Time'].mean().sort_index()

            if avg_time_by_threads.empty:
                print(f"è­¦å‘Š (æ•ˆç‡): Impl={impl}, N={target_size}, P/P_target={target_modulus} - avg_time_by_threads ä¸ºç©ºã€‚è·³è¿‡ã€‚")
                continue
                
            speedup = current_base_time_for_impl_eff / avg_time_by_threads
            
            if speedup.empty or len(speedup.index) == 0:
                print(f"è­¦å‘Š: Impl={impl}, N={target_size}, P/P_target={target_modulus} - speedup æˆ– speedup.index ä¸ºç©ºï¼Œè·³è¿‡æ•ˆç‡è®¡ç®—ã€‚")
                continue

            # ç¡®ä¿speedupæ˜¯ä¸€ç»´Series
            if isinstance(speedup.values, np.ndarray) and speedup.values.ndim > 1:
                print(f"è­¦å‘Š: Impl={impl}, N={target_size}, P/P_target={target_modulus} - speedupæ•°æ®æ˜¯å¤šç»´çš„ï¼Œå°†å±•å¹³å¤„ç†ã€‚")
                speedup = speedup.iloc[:, 0] if speedup.values.shape[1] > 0 else speedup.iloc[:, -1]
            
            s_values = speedup.values
            s_index = speedup.index
            divisor_values = s_index.to_numpy(dtype=float)

            if len(s_values) != len(divisor_values):
                print(f"CRITICAL ERROR: Impl={impl}, N={target_size}, P/P_target={target_modulus} - speedupå€¼ ({len(s_values)}) ä¸ç´¢å¼•å€¼ ({len(divisor_values)}) é•¿åº¦ä¸åŒ¹é…ã€‚è·³è¿‡æ•ˆç‡è®¡ç®—ã€‚")
                continue
            
            # ç¡®ä¿s_valuesæ˜¯ä¸€ç»´æ•°ç»„
            if isinstance(s_values, np.ndarray) and s_values.ndim > 1:
                s_values = s_values.flatten()[:len(divisor_values)]
            
            efficiency_values = np.full_like(s_values, np.nan, dtype=float)
            non_zero_divisor_mask = divisor_values != 0
            
            if np.any(~non_zero_divisor_mask):
                 print(f"è­¦å‘Š: Impl={impl}, N={target_size}, P/P_target={target_modulus} - ç´¢å¼•ä¸­å‘ç°0å€¼çº¿ç¨‹æ•°ã€‚è¿™äº›ç‚¹çš„æ•ˆç‡å°†ä¸ºNaNã€‚")

            efficiency_values[non_zero_divisor_mask] = s_values[non_zero_divisor_mask] / divisor_values[non_zero_divisor_mask]
            efficiency = pd.Series(efficiency_values, index=s_index)
            
            plt.plot(efficiency.index, efficiency.values, marker='s', linestyle='-', label=impl.replace('ntt_', '').replace('_arbitrary',''))

        plt.title(f'å¹¶è¡Œæ•ˆç‡ - {plot_title_suffix}{" (è¿‘ä¼¼åŸºå‡†)" if base_time_is_approximate else ""}', fontsize=14)
        plt.xlabel('çº¿ç¨‹æ•°', fontsize=12)
        plt.ylabel('å¹¶è¡Œæ•ˆç‡ (Efficiency)', fontsize=12)
        plt.legend()
        plt.grid(True)
        if unique_threads:
            plt.xticks(unique_threads)
        plt.ylim(0, 1.1)

        plt.tight_layout(pad=3.0)
        fig_path = os.path.join(OUTPUT_DIR, f"scalability_charts_{filename_suffix}_chinese.png")
        plt.savefig(fig_path)
        plt.close()
        scalability_chart_paths[f"scalability_{filename_suffix}"] = fig_path
        print(f"å¯æ‰©å±•æ€§å›¾è¡¨å·²ä¿å­˜åˆ°: {fig_path}")
        
    return scalability_chart_paths

def generate_detailed_comparison_charts(data):
    if data is None or data.empty:
        print("æ— æ•°æ®å¯ä¾›ç”Ÿæˆè¯¦ç»†å¯¹æ¯”å›¾è¡¨ã€‚")
        return {}

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    detailed_chart_paths = {}

    for is_crt in [False, True]:
        current_data = data[data['FullImpl'].str.contains('crt_arbitrary') == is_crt].copy()
        if current_data.empty:
            type_str = "CRT" if is_crt else "æ™®é€š"
            print(f"æ— {type_str}NTTæ•°æ®å¯ä¾›ç”Ÿæˆè¯¦ç»†å¯¹æ¯”å›¾ã€‚")
            continue
        
        unique_combinations = current_data[['Modulus', 'Size']].drop_duplicates().to_records(index=False)

        for mod_val, size_val in unique_combinations:
            subset_data = current_data[(current_data['Modulus'] == mod_val) & (current_data['Size'] == size_val)]
            if subset_data.empty:
                continue

            pivot_table = subset_data.pivot_table(index='FullImpl', columns='Threads', values='Time', aggfunc='mean')
            
            if pivot_table.empty:
                print(f"è­¦å‘Š: N={size_val}, P={mod_val} çš„æ•°æ®æ— æ³•ç”Ÿæˆé€è§†è¡¨ï¼Œè·³è¿‡æ­¤å›¾è¡¨ã€‚")
                continue

            num_impls = len(pivot_table.index)
            num_threads_groups = len(pivot_table.columns)
            

            pivot_table.plot(kind='bar', figsize=(max(10, num_impls * 1.5), 7), colormap='terrain')
            
            type_str = "CRT" if is_crt else "æ™®é€š"
            mod_display = f"P_target={mod_val}" if is_crt else f"P={mod_val}"
            plt.title(f'{type_str}NTTæ€§èƒ½å¯¹æ¯” (N={size_val}, {mod_display})', fontsize=16)
            plt.xlabel('å®ç°æ–¹æ³•', fontsize=14)
            plt.ylabel('å¹³å‡æ‰§è¡Œæ—¶é—´ (ç§’)', fontsize=14)
            plt.xticks(rotation=45, ha='right')
            plt.legend(title='çº¿ç¨‹æ•°', bbox_to_anchor=(1.02, 1), loc='upper left')
            plt.tight_layout()
            
            chart_filename = f"comparison_N{size_val}_P{str(mod_val).replace('.', '_')}_{type_str.lower()}_chinese.png"
            path = os.path.join(OUTPUT_DIR, chart_filename)
            plt.savefig(path)
            plt.close()
            detailed_chart_paths[f"detail_N{size_val}_P{mod_val}_{type_str.lower()}"] = path
            print(f"è¯¦ç»†å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜åˆ°: {path}")
            
    return detailed_chart_paths

def generate_markdown_table(df, title=""):
    if df is None or df.empty:
        return f"\\n#### {title}\\næ— æ•°æ®å¯ç”Ÿæˆè¡¨æ ¼ã€‚\\n"
    
    header = f"#### {title}\n"
    table_md = df.to_markdown(index=True)
    return header + table_md + "\n"


def generate_chinese_report(data, chart_paths, scalability_chart_paths, detailed_chart_paths):
    if data is None or data.empty:
        return "æ— æ€§èƒ½æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚"

    report_md = "## å®éªŒç»“æœä¸å¯è§†åŒ–åˆ†æ\n\n"
    report_md += "æœ¬ç« èŠ‚å°†å±•ç¤ºNTTä¸åŒå®ç°çš„æ€§èƒ½æµ‹è¯•ç»“æœï¼Œå¹¶é€šè¿‡å›¾è¡¨è¿›è¡Œå¯è§†åŒ–åˆ†æã€‚\n\n"


    report_md += "### 1. å„ç§NTTå®ç°çš„å¹³å‡æ€§èƒ½å¯¹æ¯”\n"
    report_md += "ä¸‹å›¾å±•ç¤ºäº†æœ¬æ¬¡æµ‹è¯•ä¸­æ‰€æœ‰NTTå®ç°ï¼ˆåŒ…æ‹¬ä¸²è¡Œã€pthreadã€OpenMPç‰ˆæœ¬åŠå…¶CRTå˜ä½“ï¼‰åœ¨æ‰€æœ‰æµ‹è¯•é…ç½®ä¸‹çš„å¹³å‡æ‰§è¡Œæ—¶é—´ã€‚è¿™æä¾›äº†ä¸€ä¸ªå…³äºå„ç§æ–¹æ³•æ€»ä½“æ•ˆç‡çš„åˆæ­¥å°è±¡ã€‚\n"
    if 'avg_performance' in chart_paths:
        report_md += f"![å¹³å‡æ€§èƒ½å¯¹æ¯”]({os.path.basename(chart_paths['avg_performance'])})\n"
    else:
        report_md += "å¹³å‡æ€§èƒ½å¯¹æ¯”å›¾è¡¨æœªç”Ÿæˆã€‚\n"
    
    avg_performance_series = data.groupby('FullImpl')['Time'].mean()
    if isinstance(avg_performance_series, pd.DataFrame):
        avg_performance_series = avg_performance_series.iloc[:, 0]
    avg_performance_data = avg_performance_series.sort_values(ascending=True)
    if not avg_performance_data.empty:
        best_avg_impl = avg_performance_data.index[0]
        best_avg_time = avg_performance_data.iloc[0]
        report_md += f"ä»å¹³å‡æ€§èƒ½æ¥çœ‹ï¼Œè¡¨ç°æœ€ä½³çš„å®ç°æ˜¯ **{best_avg_impl}**ï¼Œå…¶å¹³å‡æ‰§è¡Œæ—¶é—´ä¸º {best_avg_time:.4f} ç§’ã€‚\n\n"

    report_md += "### 2. é—®é¢˜è§„æ¨¡ (N) å¯¹æ€§èƒ½çš„å½±å“\n"
    report_md += "ä¸‹å›¾æ¯”è¾ƒäº†ä¸åŒå®ç°æ–¹æ³•åœ¨ä¸åŒé—®é¢˜è§„æ¨¡ (N) ä¸‹çš„æ‰§è¡Œæ—¶é—´ã€‚å¯¹äºå¹¶è¡Œå®ç°ï¼Œè¿™é‡Œå±•ç¤ºçš„æ˜¯å…¶åœ¨æµ‹è¯•ä¸­ä½¿ç”¨çš„æœ€å¤§çº¿ç¨‹æ•°ä¸‹çš„æ€§èƒ½ï¼›å¯¹äºä¸²è¡Œå®ç°ï¼Œåˆ™æ˜¯å…¶è‡ªèº«çš„æ€§èƒ½ã€‚è¿™æœ‰åŠ©äºæˆ‘ä»¬ç†è§£å„ç§ç®—æ³•çš„è®¡ç®—å¤æ‚åº¦ä»¥åŠå®ƒä»¬å¦‚ä½•éšè¾“å…¥è§„æ¨¡æ‰©å±•ã€‚\n"
    if 'size_impact' in chart_paths:
        report_md += f"![è§„æ¨¡å½±å“æ€§èƒ½]({os.path.basename(chart_paths['size_impact'])})\n"
    else:
        report_md += "é—®é¢˜è§„æ¨¡å½±å“å›¾è¡¨æœªç”Ÿæˆã€‚\n"
    report_md += "é€šå¸¸ï¼Œæ‰§è¡Œæ—¶é—´ä¼šéšç€Nçš„å¢åŠ è€Œå¢åŠ ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼ŒNTTçš„æ—¶é—´å¤æ‚åº¦ä¸»è¦ç”± $O(N \\log N)$ çš„å˜æ¢ä¸»å¯¼ã€‚\n\n"
    
    report_md += "### 3. çº¿ç¨‹æ•°å¯¹å¹¶è¡ŒNTTæ€§èƒ½çš„å½±å“\n"
    report_md += "ä¸ºäº†è¯„ä¼°å¹¶è¡ŒåŒ–æ•ˆæœï¼Œæˆ‘ä»¬è§‚å¯Ÿäº†åœ¨å›ºå®šé—®é¢˜è§„æ¨¡å’Œæ¨¡æ•°ä¸‹ï¼Œä¸åŒçº¿ç¨‹æ•°å¯¹å¹¶è¡ŒNTTï¼ˆpthread å’Œ OpenMPï¼‰æ‰§è¡Œæ—¶é—´çš„å½±å“ã€‚\n"
    
    if 'thread_impact_plain' in chart_paths:
        report_md += f"ä¸‹å›¾å±•ç¤ºäº†æ™®é€šNTTï¼ˆéCRTï¼‰çš„å¹¶è¡Œç‰ˆæœ¬éšçº¿ç¨‹æ•°å˜åŒ–çš„æ€§èƒ½è¶‹åŠ¿ï¼š\n"
        report_md += f"![çº¿ç¨‹æ•°å½±å“æ™®é€šNTTæ€§èƒ½]({os.path.basename(chart_paths['thread_impact_plain'])})\n"
    else:
        report_md += "æ™®é€šNTTçº¿ç¨‹æ•°å½±å“å›¾è¡¨æœªç”Ÿæˆã€‚\n"
        
    if 'thread_impact_crt' in chart_paths:
        report_md += f"ä¸‹å›¾å±•ç¤ºäº†CRT-NTTçš„å¹¶è¡Œç‰ˆæœ¬éšçº¿ç¨‹æ•°å˜åŒ–çš„æ€§èƒ½è¶‹åŠ¿ï¼š\n"
        report_md += f"![çº¿ç¨‹æ•°å½±å“CRT-NTTæ€§èƒ½]({os.path.basename(chart_paths['thread_impact_crt'])})\n"
    else:
        report_md += "CRT-NTTçº¿ç¨‹æ•°å½±å“å›¾è¡¨æœªç”Ÿæˆã€‚\n"
    report_md += "ç†è®ºä¸Šï¼Œå¢åŠ çº¿ç¨‹æ•°å¯ä»¥å‡å°‘æ‰§è¡Œæ—¶é—´ï¼Œä½†ç”±äºå¹¶è¡Œå¼€é”€ï¼ˆå¦‚çº¿ç¨‹åˆ›å»ºã€åŒæ­¥ã€é€šä¿¡ï¼‰å’Œä»»åŠ¡æœ¬èº«çš„å¯å¹¶è¡Œåº¦é™åˆ¶ï¼Œæ€§èƒ½æå‡å¹¶éçº¿æ€§ã€‚\n\n"

    report_md += "### 4. å¹¶è¡Œå®ç°çš„åŠ é€Ÿæ¯”ä¸æ•ˆç‡åˆ†æ\n"
    report_md += "åŠ é€Ÿæ¯” ($S_p$) å®šä¹‰ä¸ºåŒä¸€ä»»åŠ¡åœ¨å•å¤„ç†å™¨ä¸Šçš„æ‰§è¡Œæ—¶é—´ä¸åœ¨ $p$ ä¸ªå¤„ç†å™¨ä¸Šçš„æ‰§è¡Œæ—¶é—´ä¹‹æ¯”ã€‚å¹¶è¡Œæ•ˆç‡ ($E_p$) å®šä¹‰ä¸º $S_p / p$ã€‚\n"
    
    plain_scalability_key = [k for k in scalability_chart_paths if "plain" in k]
    if plain_scalability_key:
        report_md += f"ä¸‹å›¾å±•ç¤ºäº†æ™®é€šNTTå¹¶è¡Œå®ç°çš„åŠ é€Ÿæ¯”å’Œå¹¶è¡Œæ•ˆç‡ï¼š\n"
        report_md += f"![æ™®é€šNTTå¯æ‰©å±•æ€§]({os.path.basename(scalability_chart_paths[plain_scalability_key[0]])})\n"
    else:
        report_md += "æ™®é€šNTTå¯æ‰©å±•æ€§å›¾è¡¨ï¼ˆåŠ é€Ÿæ¯”å’Œæ•ˆç‡ï¼‰æœªç”Ÿæˆã€‚\n"

    crt_scalability_key = [k for k in scalability_chart_paths if "crt" in k]
    if crt_scalability_key:
        report_md += f"ä¸‹å›¾å±•ç¤ºäº†CRT-NTTå¹¶è¡Œå®ç°çš„åŠ é€Ÿæ¯”å’Œå¹¶è¡Œæ•ˆç‡ï¼š\n"
        report_md += f"![CRT-NTTå¯æ‰©å±•æ€§]({os.path.basename(scalability_chart_paths[crt_scalability_key[0]])})\n"
    else:
        report_md += "CRT-NTTå¯æ‰©å±•æ€§å›¾è¡¨ï¼ˆåŠ é€Ÿæ¯”å’Œæ•ˆç‡ï¼‰æœªç”Ÿæˆã€‚\n"
    report_md += "ç†æƒ³æƒ…å†µä¸‹ï¼ŒåŠ é€Ÿæ¯”åº”æ¥è¿‘çº¿ç¨‹æ•°ï¼Œå¹¶è¡Œæ•ˆç‡æ¥è¿‘1ã€‚å®é™…ä¸­ï¼Œç”±äºAmhdahlå®šå¾‹ä»¥åŠå¹¶è¡Œå¼€é”€ï¼Œè¿™äº›å€¼é€šå¸¸ä¼šè¾ƒä½ã€‚\n\n"
    
    report_md += "### 5. è¯¦ç»†æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”\n"
    report_md += "ä¸ºäº†æ›´ç»†è‡´åœ°åˆ†æï¼Œä»¥ä¸‹å°†å±•ç¤ºåœ¨ç‰¹å®šé—®é¢˜è§„æ¨¡Nå’Œæ¨¡æ•°Pï¼ˆæˆ–CRTçš„ç›®æ ‡æ¨¡æ•°P_targetï¼‰ç»„åˆä¸‹ï¼Œå„å®ç°æ–¹æ³•ï¼ˆåŒ…æ‹¬ä¸åŒçº¿ç¨‹æ•°ï¼‰çš„æ€§èƒ½æ•°æ®è¡¨æ ¼å’Œå¯¹æ¯”å›¾ã€‚\n\n"
    
    report_md += "#### åŸå§‹æ€§èƒ½æ•°æ®æ‘˜è¦ (å¹³å‡æ—¶é—´)\n"
    summary_table_data = data.groupby(['FullImpl', 'Size', 'Modulus', 'Threads'])['Time'].mean().reset_index()
    summary_table_data.rename(columns={'FullImpl': 'å®ç°æ–¹æ³•', 'Size': 'N', 'Modulus': 'P/P_target', 'Threads': 'çº¿ç¨‹æ•°', 'Time': 'å¹³å‡æ—¶é—´(s)'}, inplace=True)
    report_md += generate_markdown_table(summary_table_data.head(20), "æ€§èƒ½æ•°æ®é€‰æ‘˜ (å‰20æ¡)") + "\n (å®Œæ•´æ•°æ®è¯·å‚è€ƒåŸå§‹CSVæ–‡ä»¶)\n\n"


    report_md += "#### ç‰¹å®šé…ç½®ä¸‹çš„æ€§èƒ½å¯¹æ¯”å›¾\n"
    if detailed_chart_paths:
        report_md += "ä»¥ä¸‹å›¾è¡¨åˆ†åˆ«é’ˆå¯¹ä¸åŒçš„ (N, P/P_target) ç»„åˆï¼Œå¯¹æ¯”äº†å„ç§å®ç°ï¼ˆåŒ…æ‹¬ä¸åŒçº¿ç¨‹æ•°ï¼‰çš„æ€§èƒ½ï¼š\n"
        for key, path in sorted(detailed_chart_paths.items()):
            try:
                parts = key.split('_')
                n_val = [p for p in parts if p.startswith('N')][0][1:]
                p_val_str = [p for p in parts if p.startswith('P')][0][1:]
                type_val = parts[-1] if parts[-1] in ["plain", "crt"] else "æœªçŸ¥ç±»å‹"
                report_md += f"\n##### å¯¹æ¯”: N={n_val}, P/P_target={p_val_str} ({type_val.upper()})\n"
                report_md += f"![è¯¦ç»†å¯¹æ¯”: N={n_val}, P={p_val_str}, ç±»å‹={type_val}]({os.path.basename(path)})\n"
            except Exception as e:
                report_md += f"\n##### è¯¦ç»†å¯¹æ¯”å›¾\n![è¯¦ç»†å¯¹æ¯”å›¾]({os.path.basename(path)})\n (å›¾è¡¨æè¿°è§£æå¤±è´¥: {e})\n"
    else:
        report_md += "è¯¦ç»†æ€§èƒ½å¯¹æ¯”å›¾è¡¨æœªç”Ÿæˆã€‚\n"
        
    report_md += "\n---\næŠ¥å‘Šç”Ÿæˆå®Œæ¯•ã€‚\n"
    return report_md

def main():
    parser = argparse.ArgumentParser(description="ä»æ€§èƒ½æ•°æ®CSVæ–‡ä»¶ç”Ÿæˆå›¾è¡¨å’ŒMarkdownæŠ¥å‘Š")
    parser.add_argument("csv_file", help="åŒ…å«æ€§èƒ½æ•°æ®çš„CSVæ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: performance_data.csv)")
    args = parser.parse_args()

    print(f"æ­£åœ¨ä» {args.csv_file} åŠ è½½æ•°æ®...")
    perf_data = load_performance_data(args.csv_file)

    if perf_data is None or perf_data.empty:
        print(f"æœªèƒ½åŠ è½½æˆ–è§£ææ•°æ®ï¼Œæˆ–è€…æ•°æ®ä¸ºç©ºã€‚è¯·æ£€æŸ¥CSVæ–‡ä»¶: {args.csv_file}")
        return
    
    print("æ•°æ®åŠ è½½å®Œæ¯•ï¼Œå¼€å§‹ç”Ÿæˆå›¾è¡¨...")
    general_chart_paths = create_chinese_performance_charts(perf_data)
    
    scalability_chart_paths = create_chinese_scalability_chart(perf_data)
    
    detailed_chart_paths = generate_detailed_comparison_charts(perf_data)
    print("å›¾è¡¨ç”Ÿæˆå®Œæ¯•.")

    print("å¼€å§‹ç”ŸæˆMarkdownæŠ¥å‘Šå†…å®¹...")
    markdown_report_content = generate_chinese_report(perf_data, general_chart_paths, scalability_chart_paths, detailed_chart_paths)
    
    report_filename = "generated_report_content_chinese.md"
    with open(report_filename, "w", encoding="utf-8") as f:
        f.write(markdown_report_content)
    print(f"MarkdownæŠ¥å‘Šå†…å®¹å·²ä¿å­˜åˆ°: {report_filename}")

    print("\\næ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åœ¨ä»¥ä¸‹ç›®å½•ä¸­:")
    print(f"- é€šç”¨æ€§èƒ½å›¾è¡¨: {', '.join([os.path.basename(p) for p in general_chart_paths.values()])}")
    print(f"- å¯æ‰©å±•æ€§å›¾è¡¨: {', '.join([os.path.basename(p) for p in scalability_chart_paths.values()])}")
    print(f"- è¯¦ç»†å¯¹æ¯”å›¾è¡¨: {', '.join([os.path.basename(p) for p in detailed_chart_paths.values()])}")
    print(f"è¿™äº›å›¾è¡¨å‡ä½äº '{OUTPUT_DIR}/' ç›®å½•ä¸‹ã€‚")

if __name__ == "__main__":
    main() 